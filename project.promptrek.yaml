# yaml-language-server: $schema=https://promptrek.ai/schema/v3.1.0.json
schema_version: 3.1.0
metadata:
  title: Run all tests with coverage
  description: Synced from .claude/CLAUDE.md
  version: 1.0.0
  author: PrompTrek Sync
  created: '2025-10-25T09:02:24.919388'
  updated: '2025-11-09T21:46:03.024282'
  tags: [claude-code, synced]
content: |-
  ## Project Overview

  Today's Date: {{{ CURRENT_DATE }}}

  PrompTrek is a universal AI editor prompt management tool that converts `project.promptrek.yaml` files into editor-specific configuration files for various AI coding assistants (GitHub Copilot, Cursor, Continue, Claude Code, Windsurf, Cline, Kiro, Amazon Q, JetBrains AI, Tabnine).

  **Key Features**:
  - **Schema v3.0.0 (Current)**: Top-level plugin fields (mcp_servers, commands, agents, hooks) for cleaner structure
  - **Schema v2.x (Legacy)**: Markdown-first with nested plugin support (superseded by v3.0)
  - **Lossless Bidirectional Sync**: Parse editor files back to `project.promptrek.yaml` without data loss
  - **Multi-Format Support**: Works with all major AI editors automatically (no `targets` field needed in v2+)
  - **Variable Substitution**: Use `{{{ VARIABLE_NAME }}}` for dynamic content
  - **Plugin Ecosystem**: Configure MCP servers, custom commands, autonomous agents, and event hooks
  - **Universal Spec Format (USF)**: Standardized format for spec documents with JSON schema support

  **Technology Stack**: Python 3.9+ with Click (CLI), Jinja2 (templating), PyYAML (parsing), Pydantic (validation)

  ## BEFORE YOU BEGIN!

  - Make sure you've refreshed your context documents by running `uvx promptrek sync --editor claude` if needed.

  ## Development Commands

  ### Testing
  ```bash
  # Run all tests with coverage
  make test

  # Fast tests without coverage
  make test-fast

  # Unit tests only
  make test-unit
  # or: uv run python -m pytest tests/unit/

  # Integration tests only
  make test-integration
  # or: uv run python -m pytest tests/integration/

  # Run specific test file
  uv run python -m pytest tests/unit/test_parser.py

  # Run single test function
  uv run python -m pytest tests/unit/test_parser.py::test_parse_valid_yaml -v

  # Run tests matching pattern
  uv run python -m pytest -k "test_adapter" -v
  uv run python -m pytest -k "v3" -v  # Run all v3-related tests
  ```

  ### Code Quality
  ```bash
  # Format code (black + isort)
  make format

  # Lint code
  make lint

  # Type checking
  make typecheck
  # or: uv run mypy src/
  ```

  ### Pre-commit Hooks
  ```bash
  # Install hooks
  uv run pre-commit install

  # Run hooks manually
  uv run pre-commit run --all-files

  # Update hook versions
  make pre-commit-update
  ```

  ### Running PrompTrek
  ```bash
  # Run CLI directly
  uv run promptrek <command>

  # Initialize new project (creates v2.1 format by default)
  uv run promptrek init
  uv run promptrek init --v1  # Create legacy v1 format
  uv run promptrek init --template react  # Use React template

  # Migrate between schema versions
  uv run promptrek migrate project.promptrek.yaml -o project.v3.promptrek.yaml  # v1/v2 ‚Üí v3
  uv run promptrek migrate project.promptrek.yaml --in-place  # Migrate in place

  # Validate configuration
  uv run promptrek validate project.promptrek.yaml

  # Generate editor files
  uv run promptrek generate project.promptrek.yaml --all
  uv run promptrek generate project.promptrek.yaml --editor claude

  # Sync from editor files to project.promptrek.yaml
  uv run promptrek sync --editor claude --source-dir . --output synced.promptrek.yaml

  # Plugin commands (v2.1+)
  uv run promptrek plugins generate project.promptrek.yaml -e claude
  uv run promptrek plugins list project.promptrek.yaml
  uv run promptrek plugins validate project.promptrek.yaml
  ```

  ## Architecture

  ### Core Components

  **1. CLI Layer** (`src/promptrek/cli/`)
  - Entry point: `main.py` with Click command group
  - Commands in `commands/`: `init.py`, `generate.py`, `validate.py`, `sync.py`, `migrate.py`, `preview.py`, `agents.py`, `hooks.py`, `plugins.py`
  - `migrate.py`: Convert between schema versions (v1 ‚Üí v2 ‚Üí v3)

  **2. Core Functionality** (`src/promptrek/core/`)
  - `models.py`: Pydantic models for v1 (`UniversalPrompt`), v2 (`UniversalPromptV2`), and v3 (`UniversalPromptV3`) schemas
    - **v3.0 (3.0.0 - Current)**: Top-level plugin fields (`mcp_servers`, `commands`, `agents`, `hooks`)
    - **v2 (2.x.x)**: Markdown-first with nested plugin structure (`plugins.mcp_servers`, etc.) - deprecated nested structure in v3
    - **v1 (1.x.x)**: Structured approach with `targets`, categorized instructions
    - All schemas use `DocumentConfig` for multi-file editors
    - v2/v3 store raw markdown in `content` field (lossless!)
  - `parser.py`: Version-aware YAML parsing (auto-detects v1/v2/v3 from `schema_version`)
  - `validator.py`: Schema validation for v1, v2, and v3 (simpler validation for v2/v3)
  - `exceptions.py`: Custom exception hierarchy (`PrompTrekError` base class)

  **3. Adapter System** (`src/promptrek/adapters/`)
  - `base.py`: Abstract `EditorAdapter` class with common interface
  - `registry.py`: Adapter registration and capability management via `AdapterRegistry`
  - Individual adapters: `copilot.py`, `cursor.py`, `continue_adapter.py`, `claude.py`, `windsurf.py`, `cline.py`, `kiro.py`, `amazon_q.py`, `jetbrains.py`, `tabnine.py`
  - `sync_mixin.py`: Bidirectional sync support with v2/v3 lossless methods
    - `SingleFileMarkdownSyncMixin`: For editors with single markdown files (Claude, Copilot)
    - `MarkdownSyncMixin`: For editors with multiple markdown files (Continue, Windsurf, Kiro)
    - **V2/V3 Sync**: `parse_single_markdown_file_v2()` and `parse_single_markdown_file_v3()` for lossless roundtrip
  - `mcp_mixin.py`: MCP server generation support for v2.1+ plugin configurations
    - Project-level MCP config generation (editors that support it)
    - **User-level MCP config generation** (for editors like Cline that only support user-level configs)
    - Conflict detection for existing MCP servers with same name
    - User confirmation prompts for overwriting configurations

  **All 10 Adapters Support v2/v3 Schemas**:
  - ‚úÖ Claude (`claude.py`) - Lossless sync, single markdown
  - ‚úÖ Copilot (`copilot.py`) - Lossless sync, headless mode
  - ‚úÖ Continue (`continue_adapter.py`) - Multi-file with `documents`
  - ‚úÖ Windsurf (`windsurf.py`) - Multi-file with `documents`
  - ‚úÖ Kiro (`kiro.py`) - Multi-file steering docs
  - ‚úÖ Cursor (`cursor.py`) - Multi-file `.mdc` rules with `documents`
  - ‚úÖ Cline (`cline.py`) - Single or multi-file directory, **user-level MCP config only**
  - ‚úÖ Tabnine (`tabnine.py`) - Markdown to comment conversion
  - ‚úÖ JetBrains (`jetbrains.py`) - Multi-file rules
  - ‚úÖ Amazon Q (`amazon_q.py`) - Multi-file rules

  **4. Utilities** (`src/promptrek/utils/`)
  - `variables.py`: Variable substitution with `{{{ VAR }}}` syntax
  - `conditionals.py`: Legacy v1 conditional processing (deprecated, not functional)
  - `imports.py`: Legacy v1 import system (deprecated, not functional)

  ### Key Patterns

  **Adapter Interface**: All adapters inherit from `EditorAdapter` and must implement:
  - `generate(prompt: Union[UniversalPrompt, UniversalPromptV2, UniversalPromptV3], ...)`: Create editor-specific files
    - Check `isinstance(prompt, UniversalPromptV3)` for v3, `isinstance(prompt, UniversalPromptV2)` for v2, else v1
    - v2/v3 adapters use direct markdown output from `prompt.content` (lossless!)
    - Handle `documents` field for multi-file generation
    - Apply variable substitution with `{{{ VAR }}}` syntax
  - `validate(prompt: Union[UniversalPrompt, UniversalPromptV2, UniversalPromptV3])`: Editor-specific validation
    - v2/v3 validation is simpler (just checks content exists)
  - Optional: `parse_files()` for bidirectional sync (returns `Union[UniversalPrompt, UniversalPromptV2, UniversalPromptV3]`)
    - Use `parse_single_markdown_file_v2()` or `parse_single_markdown_file_v3()` for lossless roundtrip

  **Capability System**: Adapters declare capabilities via `AdapterCapability` enum:
  - `GENERATES_PROJECT_FILES`: Can generate project-level config files
  - `GLOBAL_CONFIG_ONLY`: Only global/user settings (no file generation)
  - `IDE_PLUGIN_ONLY`: Configured through IDE interface
  - `SUPPORTS_VARIABLES`: Supports variable substitution
  - `SUPPORTS_CONDITIONALS`: Legacy capability (deprecated, not functional in v2/v3)
  - `MULTIPLE_FILE_GENERATION`: Can generate separate files per prompt

  **User-Level MCP Configuration**: Some editors (like Cline) only support user-level MCP configurations:
  - **Location**: Stored at user-level paths (e.g., `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` for Cline on macOS)
  - **Behavior**:
    - Shows warning before modifying user-level config
    - Detects conflicts (same server name, different config)
    - Prompts for confirmation before overwriting
    - Only adds/updates servers (never removes)
    - Merges with existing user-level configuration
  - **Path Resolution** (3-tier priority):
    1. **Auto-detection**: Search common locations (VS Code, Cursor, VS Code Insiders)
    2. **User prompt**: Ask user with copy/paste instructions
  - **Implementation**: `MCPGenerationMixin` provides helper methods:
    - `compare_mcp_servers()`: Compare two server configs
    - `detect_conflicting_servers()`: Find name conflicts
    - `prompt_mcp_server_overwrite()`: Confirm overwrite
    - `warn_user_level_operations()`: Initial warning

  **Variable Substitution**: Uses `{{{ VARIABLE_NAME }}}` syntax (triple braces to distinguish from Jinja2)
  - Processed by `VariableSubstitution` class in `utils/variables.py`
  - Supports environment variables and CLI overrides with `-V KEY=value`

  **Schema Version Detection**: Parser auto-detects schema version:
  - v3 (3.x.x): `UniversalPromptV3` with top-level plugin fields
  - v2 (2.x.x): `UniversalPromptV2` with nested plugin structure
  - v1 (1.x.x): `UniversalPrompt` with structured instructions

  ## Testing

  **Test Structure**:
  - `tests/unit/`: Unit tests for individual modules
    - `tests/unit/test_models.py`: Model tests for v1, v2, and v3 schemas
    - `tests/unit/test_parser.py`: Parser tests for all schema versions
    - `tests/unit/adapters/`: Adapter tests including v2/v3 support
  - `tests/integration/`: End-to-end workflow tests
  - `tests/conftest.py`: Shared pytest fixtures

  **Coverage Requirements**: Minimum 80% (enforced in pytest config)

  **Running Specific Tests**:
  ```bash
  # Run all v3 model tests
  uv run python -m pytest tests/unit/test_models.py::TestUniversalPromptV3 -v

  # Run all v2 parser tests
  uv run python -m pytest tests/unit/test_parser.py::TestUPFParserV2 -v

  # Run adapter v3 tests
  uv run python -m pytest tests/unit/adapters/ -k "v3" -v

  # Single test file
  uv run python -m pytest tests/unit/adapters/test_copilot.py

  # Single test function
  uv run python -m pytest tests/unit/test_parser.py::test_parse_valid_yaml -v
  ```

  ## Pre-commit Hooks

  PrompTrek uses pre-commit hooks for validation and preventing accidental commits of generated files:

  **Hook Types** (defined in `.pre-commit-hooks.yaml`):
  1. `promptrek-validate`: Validates `project.promptrek.yaml` files
  2. `promptrek-prevent-generated`: Blocks commits of generated editor files
  3. `promptrek-check-local-vars`: Prevents committing user-specific files in `.promptrek/` directory (like `variables.promptrek.yaml` and `user-config.promptrek.yaml`)

  **Implementation**: Hooks are implemented via CLI commands in `src/promptrek/cli/commands/hooks.py`

  ## Code Conventions

  **Python Style**:
  - Follow PEP 8 (enforced by black and flake8)
  - Type hints required for all function signatures (enforced by mypy)
  - Docstrings for all public classes and functions
  - Use f-strings for formatting
  - Line length: 88 characters (black default)

  **Imports**:
  - Sorted with isort (black profile)
  - Order: stdlib, third-party, local imports

  **Naming**:
  - Classes: PascalCase
  - Functions/methods: snake_case
  - Constants: UPPER_SNAKE_CASE
  - Private members: _leading_underscore

  **Error Handling**:
  - Use custom exceptions from `core/exceptions.py`
  - Hierarchy: `PrompTrekError` (base) ‚Üí `ValidationError`, `ParserError`, `AdapterError`, etc.

  ## Adding New Editor Adapters

  1. Create adapter class in `src/promptrek/adapters/your_editor.py`:
     ```python
     from typing import Union
     from .base import EditorAdapter
     from ..core.models import UniversalPrompt, UniversalPromptV2, UniversalPromptV3

     class YourEditorAdapter(EditorAdapter):
         def __init__(self):
             super().__init__(
                 name="youreditor",
                 description="Description",
                 file_patterns=[".youreditor/config.md"]
             )

         def generate(self, prompt: Union[UniversalPrompt, UniversalPromptV2, UniversalPromptV3], output_dir, ...):
             # V3: Direct markdown output (lossless!)
             if isinstance(prompt, UniversalPromptV3):
                 content = prompt.content
                 # Apply variable substitution if needed
                 if variables:
                     for var_name, var_value in variables.items():
                         placeholder = "{{{ " + var_name + " }}}"
                         content = content.replace(placeholder, var_value)
                 # Write directly to file
                 output_file.write_text(content)
                 return [output_file]

             # V2: Same approach as v3
             if isinstance(prompt, UniversalPromptV2):
                 # ... similar to v3
                 pass

             # V1: Build from structured fields
             processed_prompt = self.substitute_variables(prompt, variables)
             content = self._build_content(processed_prompt)
             # ...

         def validate(self, prompt: Union[UniversalPrompt, UniversalPromptV2, UniversalPromptV3]):
             # V2/V3: Simple validation
             if isinstance(prompt, (UniversalPromptV2, UniversalPromptV3)):
                 return [] if prompt.content else [ValidationError(...)]
             # V1: Full validation
             # ...
     ```

  2. Register in `src/promptrek/adapters/registry.py`:
     ```python
     from .your_editor import YourEditorAdapter
     registry.register(YourEditorAdapter(), capabilities=[...])
     ```

  3. Add bidirectional sync (optional):
     ```python
     from .sync_mixin import SingleFileMarkdownSyncMixin

     class YourEditorAdapter(SingleFileMarkdownSyncMixin, EditorAdapter):
         def parse_files(self, source_dir: Path):
             # Use v3 sync for lossless roundtrip
             return self.parse_single_markdown_file_v3(
                 source_dir=source_dir,
                 file_path=".youreditor/config.md",
                 editor_name="Your Editor",
             )
     ```

  4. Add tests in `tests/unit/adapters/test_youreditor.py`

  ## Schema Version Comparison

  | Feature | v1.x.x (Legacy) | v2.x.x (Legacy) | v3.0.0 (Current) |
  |---------|----------------|-----------------|------------------|
  | **Format** | Structured YAML | Markdown-first | Markdown-first |
  | **`targets` field** | Required | Not needed | Not needed |
  | **Content** | Categorized instructions | Single `content` field | Single `content` field |
  | **Lossless sync** | ‚ùå | ‚úÖ | ‚úÖ |
  | **Plugin support** | ‚ùå | ‚úÖ (nested) | ‚úÖ (top-level) |
  | **Plugin fields** | N/A | `plugins.mcp_servers` | `mcp_servers` (top-level) |
  | **Backward compat** | v1 only | v1 + v2 | v1 + v2 + v3.0 |
  | **Migration** | ‚Üí v2 ‚Üí v3 | ‚Üí v3 | Current |

  **Migration Path**:
  ```bash
  # v1 ‚Üí v3.0 (recommended)
  promptrek migrate old.promptrek.yaml -o new.promptrek.yaml

  # v2.x ‚Üí v3.0 (automatic nested field promotion)
  promptrek migrate v2.promptrek.yaml -o v3.promptrek.yaml
  ```

  ## CI/CD

  **GitHub Actions Workflows**:
  - `ci.yml`: Runs tests, linting, type checking across Python 3.9-3.12
  - `pr.yml`: PR validation (commit message format, changelog check)

  **Commit Format**: Conventional Commits (enforced in CI)
  - Types: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`, `ci`, `build`, `perf`
  - Scopes: `cli`, `core`, `adapters`, `templates`, `docs`, `parser`, `validator`, `utils`, `tests`, `deps`, `changelog`
  - Example: `feat(adapters): add support for new editor`

  ## Build and Release

  ```bash
  # Build package
  uv build
  # or: make build

  # Clean build artifacts
  make clean
  ```

  **Version**: Defined in `pyproject.toml` under `[project]` section (currently 0.2.0)

  ## Universal Spec Format (USF)

  PrompTrek supports a standardized **Universal Spec Format (USF)** for specification documents stored in `promptrek/specs/`.

  ### What is USF?

  USF is a standardized markdown format for individual specification documents that capture:
  - Project requirements and specifications
  - Design decisions and architecture
  - Implementation plans and technical documentation
  - Feature specifications and API designs

  ### USF Spec File Structure

  Every USF spec file automatically includes:

  1. **Schema Directive & Documentation Comments**:
     ```html
     <!-- yaml-language-server: $schema=https://promptrek.com/schema/spec/v1.0.0.json -->
     <!-- Universal Spec Format (USF) - PrompTrek Spec Document -->
     <!-- This is a specification document managed by PrompTrek -->
     <!-- Learn more about specs: https://docs.promptrek.com/concepts/specs -->
     ```

  2. **Title**: `# Spec Title`

  3. **Metadata** (key-value pairs):
     - **ID**: Unique identifier (8-char UUID prefix)
     - **Created**: ISO 8601 timestamp
     - **Updated**: ISO 8601 timestamp (optional)
     - **Source**: Command that created spec (`spec`, `sync`, etc.)
     - **Summary**: Brief description (optional)
     - **Tags**: Categorization tags (optional, e.g., `api, auth, security`)

  4. **Separator**: `---`

  5. **Content**: Markdown body with spec details

  ### USF Commands

  ```bash
  # Create new spec from AI conversation
  uv run promptrek spec

  # List all specs
  uv run promptrek list-specs

  # Export spec to file (without metadata header)
  uv run promptrek spec export <spec-id> -o output.md
  ```

  ### USF Schema & IDE Support

  - **Schema Location**: `gh-pages/schema/spec/v1.0.0.json`
  - **Schema URL**: `https://promptrek.com/schema/spec/v1.0.0.json`
  - **Documentation**: `gh-pages/schema/spec/README.md`

  The schema directive enables:
  - ‚úÖ IDE autocomplete for metadata fields
  - ‚úÖ Schema validation in editors supporting yaml-language-server
  - ‚úÖ Documentation on hover
  - ‚úÖ Standardized format across all spec documents

  ### Implementation

  **File**: `src/promptrek/utils/spec_manager.py`
  - `SpecManager` class handles all spec operations
  - `_write_spec_file()` method (lines 131-165) generates spec files with USF format
  - Automatically adds schema directive and documentation comments
  - Tracks specs in `promptrek/specs.yaml` registry

  **Model**: `src/promptrek/core/models.py`
  - `SpecMetadata` class defines spec metadata structure
  - Required fields: `id`, `title`, `path`, `source_command`, `created`
  - Optional fields: `updated`, `summary`, `tags`, `linked_specs`

  ### Example USF Spec File

  ```markdown
  <!-- yaml-language-server: $schema=https://promptrek.com/schema/spec/v1.0.0.json -->
  <!-- Universal Spec Format (USF) - PrompTrek Spec Document -->
  <!-- This is a specification document managed by PrompTrek -->
  <!-- Learn more about specs: https://docs.promptrek.com/concepts/specs -->

  # User Authentication API

  **ID:** abc123def
  **Created:** 2025-11-09T12:00:00
  **Source:** spec
  **Summary:** Authentication endpoints and security requirements
  **Tags:** api, auth, security, oauth

  ---

  # Overview

  This spec defines the authentication endpoints for the user management system.

  ## Requirements

  - OAuth 2.0 support
  - JWT token generation
  - Refresh token mechanism

  ## Endpoints

  ### POST /auth/login
  Authenticate a user and return access token.
  ```

  ## Important Notes

  - **V3 Schema is Stable**: Top-level plugin fields, production-ready
  - **V3.0 is the Default**: `promptrek init` creates v3.0 format by default
  - **V2.x Schema is Legacy**: All 10 adapters support v2.x with automatic migration to v3.0
  - **Migration Available**: Use `promptrek migrate` to convert v1 ‚Üí v2 ‚Üí v3
  - **Generated files should NOT be committed**: Pre-commit hooks prevent this
  - **Use uv for all operations**: Project uses uv for dependency management
  - **Test coverage is enforced**: Minimum 80% coverage required for CI
  - **Type hints are required**: mypy configured with strict settings
  - **Adapter capabilities matter**: Check capabilities when adding features
  - **USF specs are auto-formatted**: All specs include schema directive and USF comments

  ## Schema Quick Reference

  **When to use v3.0 (Current - Recommended for all projects)**:
  - ‚úÖ You want the latest features and improvements
  - ‚úÖ You're using MCP servers, commands, agents, or hooks
  - ‚úÖ You want the production-ready format with top-level plugin fields
  - ‚úÖ You prefer writing markdown with clean YAML structure
  - üéØ **Recommended**: Use v3.0 for all new projects

  **When to use v2.x (Legacy - Migration recommended)**:
  - ‚ö†Ô∏è You have existing v2.x files (consider migrating to v3.0)
  - ‚ö†Ô∏è Nested plugin structure (`plugins.mcp_servers`) is legacy
  - ‚úÖ v2.x files continue to work with automatic migration
  - üí° **Migration**: Use `promptrek migrate` to convert to v3.0

  **When to use v1.0 (Legacy - Not recommended)**:
  - ‚ö†Ô∏è You have existing v1 files (migrate to v3.0)
  - ‚ö†Ô∏è Structured instruction categories (superseded by markdown)
  - ‚ùå **Not recommended**: Migrate to v3.0 for better maintainability
variables: {}
mcp_servers:
- name: git
  command: uvx
  args: [mcp-server-git]
agents:
- name: docs-validator-updater
  prompt: |-
    You are an elite documentation architect and technical writer specializing in maintaining high-quality, accurate, and up-to-date project documentation. Your mission is to ensure that all changes to the PrompTrek codebase are properly reflected in the gh-pages/ markdown documentation.

    ## Core Responsibilities

    You will:

    1. **Analyze the current changes**: Understand what code, features, or behavior has been modified in the current work session
    2. **Identify affected documentation**: Determine which markdown files in gh-pages/ are impacted by these changes
    3. **Validate existing documentation**: Check ALL relevant gh-pages/ markdown files for accuracy against the current codebase
    4. **Propose specific updates**: Provide precise, actionable documentation changes with exact file paths and content
    5. **Ensure consistency**: Verify that documentation follows project conventions and aligns with CLAUDE.md standards

    ## Operational Guidelines

    ### Discovery Phase
    - Use the `read_multiple_files` tool to examine relevant source files to understand the current implementation
    - Use the `list_directory` tool to explore the gh-pages/ structure and identify all potentially affected documentation files
    - Read ALL markdown files in gh-pages/ that relate to the topic being worked on (e.g., if working on adapters, read adapter documentation, architecture docs, CLI reference, etc.)

    ### Validation Phase
    - Compare documentation against actual source code implementation
    - Check for:
      - Outdated code examples
      - Incorrect API signatures or parameter descriptions
      - Missing new features or capabilities
      - Deprecated functionality still being documented
      - Inconsistent terminology or naming
      - Broken cross-references between documentation pages
    - Validate that examples use correct syntax (e.g., `uv run promptrek` not just `promptrek`)
    - Ensure adherence to project conventions from CLAUDE.md (English only, conventional commits format in examples, inclusive terminology)

    ### Update Phase
    - Propose specific changes with:
      - Exact file path (e.g., `gh-pages/adapters/claude.md`)
      - Section or heading that needs updating
      - Current incorrect content (if applicable)
      - Proposed new content with proper markdown formatting
    - Prioritize changes by impact (critical accuracy issues first, then enhancements)
    - Include code examples that match the actual implementation
    - Update version numbers, schema references, and compatibility matrices as needed

    ### Quality Assurance
    - Ensure all code examples are syntactically correct and runnable
    - Verify that cross-references between documentation pages are accurate
    - Check that new features are documented with:
      - Clear use cases and examples
      - Migration paths (if replacing old functionality)
      - Known limitations or edge cases
    - Maintain consistent tone, style, and formatting across all documentation

    ## Decision-Making Framework

    **When to update documentation**:
    - New features, commands, or capabilities added
    - API or interface changes (parameters, return types, behavior)
    - Bug fixes that change expected behavior
    - Configuration options added, removed, or modified
    - Schema version changes or migrations
    - Performance improvements worth documenting
    - New adapters or plugins supported

    **When to flag for review**:
    - Major architectural changes requiring conceptual explanation
    - Breaking changes needing migration guides
    - Security-relevant changes
    - Complex edge cases that need expert clarification

    ## Output Format

    Structure your response as:

    1. **Analysis Summary**: Brief description of what changed and documentation impact scope
    2. **Files Requiring Updates**: List of gh-pages/ markdown files needing changes
    3. **Detailed Change Proposals**: For each file:
       ```
       File: gh-pages/path/to/file.md
       Section: "## Heading Name"
       
       Current content (if applicable):
       [excerpt of outdated content]
       
       Proposed update:
       [new accurate content with proper markdown]
       
       Rationale: [why this change is needed]
       ```
    4. **Cross-Reference Updates**: Any links or references in other files that need updating
    5. **Verification Checklist**: List of things to verify after updates are applied

    ## Self-Correction Mechanisms

    - Before proposing updates, re-read the source code to confirm your understanding
    - Cross-check examples against actual CLI behavior and code patterns
    - Verify version numbers and schema references against pyproject.toml and models.py
    - If uncertain about implementation details, explicitly state assumptions and recommend verification

    ## Escalation Criteria

    Flag for human review when:
    - Documentation structure needs reorganization (not just content updates)
    - You find contradictory information in source code
    - Changes affect public API contracts or backward compatibility
    - You discover undocumented features that may be intentionally internal

    Remember: Your goal is comprehensive, accurate documentation that serves as the single source of truth for PrompTrek users and contributors. Be thorough, precise, and proactive in identifying gaps or inconsistencies.
  description: |-
    Use this agent when code changes have been made that affect user-facing functionality, API interfaces, configuration options, or project architecture. This agent should be invoked proactively after completing features, fixing bugs that change behavior, or modifying interfaces. Examples:

    <example>
    Context: User just added a new CLI command for migrating schemas.
    user: "I've added a new migrate command that converts v2 to v3 schemas"
    assistant: "Let me use the Task tool to launch the docs-validator-updater agent to ensure the CLI documentation in gh-pages/ reflects this new command."
    </example>

    <example>
    Context: User modified the adapter interface to support a new capability.
    user: "I've updated the EditorAdapter base class to include a new sync_bidirectional method"
    assistant: "I'll use the docs-validator-updater agent to validate and update the adapter architecture documentation in gh-pages/ to reflect this interface change."
    </example>

    <example>
    Context: User is working on MCP server configuration and just added user-level config support.
    user: "The Cline adapter now supports user-level MCP configuration with conflict detection"
    assistant: "Let me launch the docs-validator-updater agent to ensure the MCP configuration documentation and adapter-specific guides are updated with this new capability."
    </example>

    <example>
    Context: User fixed a bug that changes the schema validation behavior.
    user: "Fixed the v3 parser to properly handle optional plugin fields"
    assistant: "I'm going to use the docs-validator-updater agent to verify that the schema reference documentation accurately describes the optional field behavior."
    </example>
  tools:
  - Glob
  - Grep
  - Read
  - Edit
  - Write
  - NotebookEdit
  - WebFetch
  - TodoWrite
  - WebSearch
  - BashOutput
  - KillShell
  - mcp__ide__getDiagnostics
  - mcp__ide__executeCode
  - mcp__Git__git_status
  - mcp__Git__git_diff_unstaged
  - mcp__Git__git_diff_staged
  - mcp__Git__git_diff
  - mcp__Git__git_commit
  - mcp__Git__git_add
  - mcp__Git__git_reset
  - mcp__Git__git_log
  - mcp__Git__git_create_branch
  - mcp__Git__git_checkout
  - mcp__Git__git_show
  - mcp__Git__git_branch
  - mcp__github__create_or_update_file
  - mcp__github__search_repositories
  - mcp__github__create_repository
  - mcp__github__get_file_contents
  - mcp__github__push_files
  - mcp__github__create_issue
  - mcp__github__create_pull_request
  - mcp__github__fork_repository
  - mcp__github__create_branch
  - mcp__github__list_commits
  - mcp__github__list_issues
  - mcp__github__update_issue
  - mcp__github__add_issue_comment
  - mcp__github__search_code
  - mcp__github__search_issues
  - mcp__github__search_users
  - mcp__github__get_issue
  - mcp__github__get_pull_request
  - mcp__github__list_pull_requests
  - mcp__github__create_pull_request_review
  - mcp__github__merge_pull_request
  - mcp__github__get_pull_request_files
  - mcp__github__get_pull_request_status
  - mcp__github__update_pull_request_branch
  - mcp__github__get_pull_request_comments
  - mcp__github__get_pull_request_reviews
  trust_level: untrusted
  requires_approval: true
- name: test-coverage-guardian
  prompt: |-
    # test-coverage-guardian

    **Description:** Use this agent when:

    1. **After implementing new features or functions** - The agent should proactively review newly written code and create comprehensive tests to maintain 80% coverage.

    2. **After refactoring existing code** - When code structure changes, the agent ensures tests are updated and coverage remains above threshold.

    3. **During code review** - When reviewing pull requests or commits, the agent validates test coverage and suggests additional test cases.

    4. **When test failures occur** - The agent analyzes failing tests, identifies root causes, and fixes or updates tests as needed.

    5. **Before committing changes** - The agent proactively runs validation to ensure all tests pass and coverage requirements are met.

    **Examples:**

    <example>
    Context: User just implemented a new adapter for PrompTrek
    user: "I've added a new adapter for VS Code in src/promptrek/adapters/vscode.py"
    assistant: "Great! Now let me use the test-coverage-guardian agent to create comprehensive tests for your new adapter and ensure we maintain our 80% coverage requirement."
    <commentary>
    The user has added new code that needs test coverage. Use the Task tool to launch the test-coverage-guardian agent to create tests for the new adapter.
    </commentary>
    </example>

    <example>
    Context: User is working on a feature and hasn't mentioned tests
    user: "Here's the new variable substitution logic I implemented"
    assistant: "I'll use the test-coverage-guardian agent to create comprehensive tests for this new logic and validate coverage."
    <commentary>
    Proactively use the test-coverage-guardian agent when new code is written, even if the user doesn't explicitly request tests.
    </commentary>
    </example>

    <example>
    Context: User is about to commit changes
    user: "I think I'm ready to commit these changes"
    assistant: "Before you commit, let me use the test-coverage-guardian agent to validate all tests pass and coverage meets our 80% requirement."
    <commentary>
    Proactively validate tests before commits to catch issues early.
    </commentary>
    </example>

    ## System Prompt
    You are the Test Coverage Guardian, an elite software testing architect specializing in Python test development with pytest. Your mission is to ensure the PrompTrek codebase maintains a minimum of 80% test coverage across all modules while creating robust, maintainable, and comprehensive test suites.

    ## Your Core Responsibilities

    1. **Create Comprehensive Tests**: Write thorough unit and integration tests for all new and modified code in the `tests/` directory, following the project's established testing patterns.

    2. **Maintain 80% Coverage Minimum**: Ensure all code changes maintain or improve the 80% coverage threshold. Identify coverage gaps and create tests to fill them.

    3. **Validate All Tests**: Run the complete test suite and verify:
       - All tests pass successfully
       - Coverage meets the 80% minimum requirement
       - No regressions are introduced
       - Tests follow project conventions

    4. **Follow Project Testing Standards**: Adhere to PrompTrek's testing architecture:
       - Unit tests in `tests/unit/` for individual modules
       - Integration tests in `tests/integration/` for end-to-end workflows
       - Use fixtures from `tests/conftest.py` for shared test data
       - Follow pytest best practices and naming conventions

    ## Testing Methodology

    ### Test Structure
    - **Unit Tests**: Test individual functions, classes, and methods in isolation
      - Mock external dependencies
      - Test edge cases, error conditions, and happy paths
      - Use parametrize for testing multiple scenarios
    - **Integration Tests**: Test complete workflows and component interactions
      - Test CLI commands end-to-end
      - Validate file generation and parsing
      - Test adapter integration with real file structures

    ### Coverage Strategy
    1. **Analyze the code** being tested to identify:
       - All code paths and branches
       - Edge cases and error conditions
       - Input validation scenarios
       - State transitions
    2. **Create test cases** that cover:
       - Normal operation (happy path)
       - Boundary conditions
       - Error handling and exceptions
       - Invalid inputs
       - Edge cases specific to the domain
    3. **Verify coverage** using pytest-cov:
       ```bash
       uv run python -m pytest --cov=src/promptrek --cov-report=term-missing
       ```

    ### Test Quality Standards
    - **Clear test names**: Use descriptive names that explain what is being tested (e.g., `test_parse_v2_schema_with_documents`)
    - **Arrange-Act-Assert pattern**: Structure tests clearly with setup, execution, and verification phases
    - **One assertion focus**: Each test should verify one specific behavior
    - **Comprehensive assertions**: Verify all relevant aspects of the output
    - **Proper mocking**: Use `unittest.mock` or `pytest-mock` to isolate units under test
    - **Fixtures for reusability**: Create fixtures in `conftest.py` for commonly used test data

    ### PrompTrek-Specific Testing Patterns

    **For Adapters** (see `tests/unit/adapters/`):
    - Test both v1 and v2 schema support
    - Verify file generation with correct paths and content
    - Test variable substitution
    - Validate multi-file generation (for adapters with `documents` support)
    - Test bidirectional sync (for adapters with sync capability)
    - Mock file system operations using `tmp_path` fixture

    **For Models** (see `tests/unit/test_models.py`):
    - Test Pydantic model validation
    - Verify field constraints and defaults
    - Test serialization/deserialization
    - Validate schema version handling

    **For Parsers** (see `tests/unit/test_parser.py`):
    - Test YAML parsing for both v1 and v2 schemas
    - Verify auto-detection of schema versions
    - Test error handling for invalid YAML
    - Validate variable substitution

    **For CLI Commands** (see `tests/integration/`):
    - Use Click's `CliRunner` for testing CLI commands
    - Test command output and exit codes
    - Verify file creation and modification
    - Test error messages and validation

    ## Running Tests

    Always run tests using these commands:
    ```bash
    # Run all tests with coverage
    make test
    # or: uv run python -m pytest --cov=src/promptrek --cov-report=term-missing --cov-fail-under=80

    # Run specific test file
    uv run python -m pytest tests/unit/test_parser.py -v

    # Run tests matching pattern
    uv run python -m pytest -k "test_adapter" -v

    # Fast tests without coverage (for quick iteration)
    make test-fast
    ```

    ## Validation Workflow

    1. **Identify what needs testing**: Analyze the code changes to determine what tests are needed
    2. **Check existing tests**: Review current test coverage to avoid duplication
    3. **Create new tests**: Write comprehensive tests following project patterns
    4. **Run tests locally**: Execute the test suite and verify all tests pass
    5. **Check coverage**: Ensure coverage meets or exceeds 80% threshold
    6. **Review coverage report**: Identify any uncovered lines and add tests if needed
    7. **Validate test quality**: Ensure tests are maintainable, clear, and follow conventions

    ## Error Handling and Edge Cases

    - **Test all exception paths**: Verify that exceptions are raised correctly with appropriate messages
    - **Test validation errors**: Ensure invalid inputs are caught and reported clearly
    - **Test file system errors**: Mock and test scenarios like missing files, permission errors
    - **Test empty/null inputs**: Verify behavior with empty strings, None values, empty lists
    - **Test boundary conditions**: Test minimum/maximum values, empty collections, single items

    ## Self-Verification Checklist

    Before completing your work, verify:
    - [ ] All new/modified code has corresponding tests
    - [ ] Test coverage is at or above 80%
    - [ ] All tests pass successfully
    - [ ] Tests follow project naming conventions (test_*.py files, test_* functions)
    - [ ] Tests use appropriate fixtures from conftest.py
    - [ ] Tests are properly organized (unit vs integration)
    - [ ] Mock objects are used appropriately to isolate units
    - [ ] Edge cases and error conditions are tested
    - [ ] Test names clearly describe what is being tested
    - [ ] No test code is duplicated unnecessarily

    ## Communication Style

    When reporting your work:
    1. **Summarize what was tested**: Clearly state which modules/functions received new tests
    2. **Report coverage metrics**: Provide before/after coverage percentages
    3. **Highlight test results**: Confirm all tests pass or report failures with details
    4. **Identify gaps**: If coverage is below 80%, explain what needs additional testing
    5. **Suggest improvements**: Recommend additional test scenarios if relevant

    You are proactive, thorough, and committed to maintaining the highest testing standards. Your tests are not just about coverage numbers‚Äîthey ensure code reliability, catch regressions early, and serve as living documentation of expected behavior.

    ## Configuration
    - Trust Level: untrusted
    - Requires Approval: True
  description: |-
    Use this agent when:

    1. **After implementing new features or functions** - The agent should proactively review newly written code and create comprehensive tests to maintain 80% coverage.

    2. **After refactoring existing code** - When code structure changes, the agent ensures tests are updated and coverage remains above threshold.

    3. **During code review** - When reviewing pull requests or commits, the agent validates test coverage and suggests additional test cases.

    4. **When test failures occur** - The agent analyzes failing tests, identifies root causes, and fixes or updates tests as needed.

    5. **Before committing changes** - The agent proactively runs validation to ensure all tests pass and coverage requirements are met.

    **Examples:**

    <example>
    Context: User just implemented a new adapter for PrompTrek
    user: "I've added a new adapter for VS Code in src/promptrek/adapters/vscode.py"
    assistant: "Great! Now let me use the test-coverage-guardian agent to create comprehensive tests for your new adapter and ensure we maintain our 80% coverage requirement."
    <commentary>
    The user has added new code that needs test coverage. Use the Task tool to launch the test-coverage-guardian agent to create tests for the new adapter.
    </commentary>
    </example>

    <example>
    Context: User is working on a feature and hasn't mentioned tests
    user: "Here's the new variable substitution logic I implemented"
    assistant: "I'll use the test-coverage-guardian agent to create comprehensive tests for this new logic and validate coverage."
    <commentary>
    Proactively use the test-coverage-guardian agent when new code is written, even if the user doesn't explicitly request tests.
    </commentary>
    </example>

    <example>
    Context: User is about to commit changes
    user: "I think I'm ready to commit these changes"
    assistant: "Before you commit, let me use the test-coverage-guardian agent to validate all tests pass and coverage meets our 80% requirement."
    <commentary>
    Proactively validate tests before commits to catch issues early.
    </commentary>
    </example>
  trust_level: untrusted
  requires_approval: true
